{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders with PyTorch\n",
    "\n",
    "!!! tip \"Run Jupyter Notebook\"\n",
    "    You can run the code for this section in this [jupyter notebook link](https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/pytorch_autoencoder.ipynb).\n",
    "    \n",
    "## About Autoencoders\n",
    "\n",
    "### Feedforward Neural Network (FNN) to Autoencoders (AEs)\n",
    "- Autoencoder is a form of **unsupervised learning**.\n",
    "    - This is a big deviation from what we have been doing: classification and regression which are under supervised learning.\n",
    "    - There are no labels required, inputs are used as labels.\n",
    "    \t- This is a bit mind-boggling for some, but there're many conrete use cases as you'll soon realize.\n",
    "    \t- Just a quick preview of use cases we will be covering:\n",
    "    \t\t- Denoising overcomplete AEs: recreate images without the random noises originally injected.\n",
    "    \t\t- Undercomplete AEs for anomaly detection: use AEs for credit card fraud detection via anomaly detection.\n",
    "    \t\t- Variational AEs for creating synthetic faces: with a convolutional VAEs, we can make fake faces.\n",
    "- An autoencoder's purpose is to learn an approximation of the identity function (mapping $x$ to $\\hat x$).\n",
    "    - Essentially we are trying to learn a function that can take our input $x$ and recreate it $\\hat x$.\n",
    "        - Technically we can do an exact recreation of our in-sample input if we use a very wide and deep neural network.\n",
    "\n",
    "![](./images/autoencoder_0.png)\n",
    "\n",
    "### Undercomplete and Overcomplete Autoencoders\n",
    "- When we highlighted some use cases, did you notice how we mentioned undercomplete and autocomplete AEs?\n",
    "- The only difference between the two is in the encoding output's size.\n",
    "\t- In the diagram above, this refers to the encoding output's size after our first affine function (yellow box) and non-linear function (pink box).\n",
    "- **Undercomplete AEs: smaller**\n",
    "\t- This is when our encoding output's dimension is **smaller** than our input's dimension.\n",
    "\t\t- Essentially we reduced the dimension of our data (dimensionality reduction) with an undercomplete AE\n",
    "- **Overcomplete AEs: larger**\n",
    "\t- This is when our encoding output's dimension is **larger** than our input's dimension\n",
    "\t\t- Essentially we increased the dimension of our data with an overcomplete AE\n",
    "        \n",
    "### Fully-connected and Convolutional Autoencoders\n",
    "- Another important point is that, in our diagram we've used the example of our Feedforward Neural Networks (FNN) where we use fully-connected layers. \n",
    "\t- This is called Fully-connected AE.\n",
    "- However, we can easily swap those fully-connected layers with convolutional layers.\n",
    "\t- This is called Convolutional AE.\n",
    "\n",
    "## Autoencoders Series\n",
    "- We'll be covering a series of autoencoders in this order\n",
    "\t- Fully-connected Overcomplete Autoencoder (AEs): Denoising Images\n",
    "\t- Fully-connected Undercomplete Autoencoder (AEs): Credit Card Fraud Detection\n",
    "\t- Convolutional Overcomplete Variational Autoencoder (VAEs): Generate Fake Human Faces\n",
    "\t- Convolutional Overcomplete Adversarial Autoencoder (AAEs): Generate Fake Human Faces\n",
    "\t- Generative Adversarial Networks (GANs): Generate Better Fake Human Faces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
